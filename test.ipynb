{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from rl.agents import DQNAgent \n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "\n",
    "import gymnasium as gym\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "states = env.observation_space.shape[0]\n",
    "actions = env.action_space.n\n",
    "\n",
    "print(states)\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_5 (Flatten)         (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 24)                120       \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 24)                600       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 2)                 50        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 770\n",
      "Trainable params: 770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(1, states)))\n",
    "model.add(Dense(24, activation=\"relu\"))\n",
    "model.add(Dense(24, activation=\"relu\"))\n",
    "model.add(Dense(actions, activation=\"linear\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DQNAgent(\n",
    "    model=model,\n",
    "    memory=SequentialMemory(limit=50000, window_length=1),\n",
    "    policy=BoltzmannQPolicy(),\n",
    "    nb_actions=actions,\n",
    "    nb_steps_warmup=10,\n",
    "    target_model_update=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TimeLimit<OrderEnforcing<PassiveEnvChecker<CartPoleEnv<CartPole-v1>>>>>\n",
      "Training for 50000 steps ...\n",
      "Interval 1 (0 steps performed)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected flatten_5_input to have shape (1, 4) but got array with shape (1, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mprint\u001b[39m(env)\n\u001b[0;32m      3\u001b[0m agent\u001b[39m.\u001b[39mcompile(Adam(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m), metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mmae\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m----> 4\u001b[0m agent\u001b[39m.\u001b[39;49mfit(env, nb_steps\u001b[39m=\u001b[39;49m\u001b[39m50000\u001b[39;49m, visualize\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Xteve Sing\\.conda\\envs\\rltest\\lib\\site-packages\\rl\\core.py:168\u001b[0m, in \u001b[0;36mAgent.fit\u001b[1;34m(self, env, nb_steps, action_repetition, callbacks, verbose, visualize, nb_max_start_steps, start_step_policy, log_interval, nb_max_episode_steps)\u001b[0m\n\u001b[0;32m    165\u001b[0m callbacks\u001b[39m.\u001b[39mon_step_begin(episode_step)\n\u001b[0;32m    166\u001b[0m \u001b[39m# This is were all of the work happens. We first perceive and compute the action\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[39m# (forward step) and then use the reward to improve (backward step).\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m action \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(observation)\n\u001b[0;32m    169\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     action \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessor\u001b[39m.\u001b[39mprocess_action(action)\n",
      "File \u001b[1;32mc:\\Users\\Xteve Sing\\.conda\\envs\\rltest\\lib\\site-packages\\rl\\agents\\dqn.py:224\u001b[0m, in \u001b[0;36mDQNAgent.forward\u001b[1;34m(self, observation)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, observation):\n\u001b[0;32m    222\u001b[0m     \u001b[39m# Select an action.\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory\u001b[39m.\u001b[39mget_recent_state(observation)\n\u001b[1;32m--> 224\u001b[0m     q_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_q_values(state)\n\u001b[0;32m    225\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n\u001b[0;32m    226\u001b[0m         action \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy\u001b[39m.\u001b[39mselect_action(q_values\u001b[39m=\u001b[39mq_values)\n",
      "File \u001b[1;32mc:\\Users\\Xteve Sing\\.conda\\envs\\rltest\\lib\\site-packages\\rl\\agents\\dqn.py:68\u001b[0m, in \u001b[0;36mAbstractDQNAgent.compute_q_values\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_q_values\u001b[39m(\u001b[39mself\u001b[39m, state):\n\u001b[1;32m---> 68\u001b[0m     q_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_batch_q_values([state])\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m     69\u001b[0m     \u001b[39massert\u001b[39;00m q_values\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnb_actions,)\n\u001b[0;32m     70\u001b[0m     \u001b[39mreturn\u001b[39;00m q_values\n",
      "File \u001b[1;32mc:\\Users\\Xteve Sing\\.conda\\envs\\rltest\\lib\\site-packages\\rl\\agents\\dqn.py:63\u001b[0m, in \u001b[0;36mAbstractDQNAgent.compute_batch_q_values\u001b[1;34m(self, state_batch)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_batch_q_values\u001b[39m(\u001b[39mself\u001b[39m, state_batch):\n\u001b[0;32m     62\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_state_batch(state_batch)\n\u001b[1;32m---> 63\u001b[0m     q_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict_on_batch(batch)\n\u001b[0;32m     64\u001b[0m     \u001b[39massert\u001b[39;00m q_values\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (\u001b[39mlen\u001b[39m(state_batch), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnb_actions)\n\u001b[0;32m     65\u001b[0m     \u001b[39mreturn\u001b[39;00m q_values\n",
      "File \u001b[1;32mc:\\Users\\Xteve Sing\\.conda\\envs\\rltest\\lib\\site-packages\\keras\\engine\\training_v1.py:1304\u001b[0m, in \u001b[0;36mModel.predict_on_batch\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   1299\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m   1300\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`predict_on_batch` is not supported for models distributed \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1301\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwith tf.distribute.Strategy.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1302\u001b[0m     )\n\u001b[0;32m   1303\u001b[0m \u001b[39m# Validate and standardize user data.\u001b[39;00m\n\u001b[1;32m-> 1304\u001b[0m inputs, _, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_standardize_user_data(\n\u001b[0;32m   1305\u001b[0m     x, extract_tensors_from_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m   1306\u001b[0m )\n\u001b[0;32m   1307\u001b[0m \u001b[39m# If `self._distribution_strategy` is True, then we are in a replica\u001b[39;00m\n\u001b[0;32m   1308\u001b[0m \u001b[39m# context at this point.\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_eagerly \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_distribution_strategy:\n",
      "File \u001b[1;32mc:\\Users\\Xteve Sing\\.conda\\envs\\rltest\\lib\\site-packages\\keras\\engine\\training_v1.py:2649\u001b[0m, in \u001b[0;36mModel._standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2640\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   2641\u001b[0m     \u001b[39mnot\u001b[39;00m run_eagerly\n\u001b[0;32m   2642\u001b[0m     \u001b[39mand\u001b[39;00m is_build_called\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2645\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(_is_symbolic_tensor(v) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m all_inputs)\n\u001b[0;32m   2646\u001b[0m ):\n\u001b[0;32m   2647\u001b[0m     \u001b[39mreturn\u001b[39;00m [], [], \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 2649\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_standardize_tensors(\n\u001b[0;32m   2650\u001b[0m     x,\n\u001b[0;32m   2651\u001b[0m     y,\n\u001b[0;32m   2652\u001b[0m     sample_weight,\n\u001b[0;32m   2653\u001b[0m     run_eagerly\u001b[39m=\u001b[39;49mrun_eagerly,\n\u001b[0;32m   2654\u001b[0m     dict_inputs\u001b[39m=\u001b[39;49mdict_inputs,\n\u001b[0;32m   2655\u001b[0m     is_dataset\u001b[39m=\u001b[39;49mis_dataset,\n\u001b[0;32m   2656\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[0;32m   2657\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   2658\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Xteve Sing\\.conda\\envs\\rltest\\lib\\site-packages\\keras\\engine\\training_v1.py:2690\u001b[0m, in \u001b[0;36mModel._standardize_tensors\u001b[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   2687\u001b[0m \u001b[39m# Standardize the inputs.\u001b[39;00m\n\u001b[0;32m   2688\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(x, (tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset, tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset)):\n\u001b[0;32m   2689\u001b[0m     \u001b[39m# TODO(fchollet): run static checks with dataset output shape(s).\u001b[39;00m\n\u001b[1;32m-> 2690\u001b[0m     x \u001b[39m=\u001b[39m training_utils_v1\u001b[39m.\u001b[39;49mstandardize_input_data(\n\u001b[0;32m   2691\u001b[0m         x,\n\u001b[0;32m   2692\u001b[0m         feed_input_names,\n\u001b[0;32m   2693\u001b[0m         feed_input_shapes,\n\u001b[0;32m   2694\u001b[0m         check_batch_axis\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,  \u001b[39m# Don't enforce the batch size.\u001b[39;49;00m\n\u001b[0;32m   2695\u001b[0m         exception_prefix\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39minput\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   2696\u001b[0m     )\n\u001b[0;32m   2698\u001b[0m \u001b[39m# Get typespecs for the input data and sanitize it if necessary.\u001b[39;00m\n\u001b[0;32m   2699\u001b[0m \u001b[39m# TODO(momernick): This should be capable of doing full input validation\u001b[39;00m\n\u001b[0;32m   2700\u001b[0m \u001b[39m# at all times - validate that this is so and refactor the\u001b[39;00m\n\u001b[0;32m   2701\u001b[0m \u001b[39m# standardization code.\u001b[39;00m\n\u001b[0;32m   2702\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset):\n",
      "File \u001b[1;32mc:\\Users\\Xteve Sing\\.conda\\envs\\rltest\\lib\\site-packages\\keras\\engine\\training_utils_v1.py:733\u001b[0m, in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    727\u001b[0m             \u001b[39mfor\u001b[39;00m dim, ref_dim \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(data_shape, shape):\n\u001b[0;32m    728\u001b[0m                 \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    729\u001b[0m                     ref_dim \u001b[39m!=\u001b[39m dim\n\u001b[0;32m    730\u001b[0m                     \u001b[39mand\u001b[39;00m ref_dim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    731\u001b[0m                     \u001b[39mand\u001b[39;00m dim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    732\u001b[0m                 ):\n\u001b[1;32m--> 733\u001b[0m                     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    734\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mError when checking \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    735\u001b[0m                         \u001b[39m+\u001b[39m exception_prefix\n\u001b[0;32m    736\u001b[0m                         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m: expected \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    737\u001b[0m                         \u001b[39m+\u001b[39m names[i]\n\u001b[0;32m    738\u001b[0m                         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m to have shape \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    739\u001b[0m                         \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(shape)\n\u001b[0;32m    740\u001b[0m                         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m but got array with shape \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    741\u001b[0m                         \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(data_shape)\n\u001b[0;32m    742\u001b[0m                     )\n\u001b[0;32m    743\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected flatten_5_input to have shape (1, 4) but got array with shape (1, 2)"
     ]
    }
   ],
   "source": [
    "\n",
    "print()\n",
    "\n",
    "agent.compile(Adam(learning_rate=0.001), metrics=[\"mae\"])\n",
    "agent.fit(env, nb_steps=50000, visualize=False, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 10 episodes ...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected flatten_4_input to have shape (1, 4) but got array with shape (1, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mtest(env, nb_episodes\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, visualize\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39mmean(results\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mepisode_reward\u001b[39m\u001b[39m'\u001b[39m]))\n",
      "File \u001b[1;32mc:\\Users\\Xteve Sing\\.conda\\envs\\rltest\\lib\\site-packages\\rl\\core.py:341\u001b[0m, in \u001b[0;36mAgent.test\u001b[1;34m(self, env, nb_episodes, action_repetition, callbacks, visualize, nb_max_episode_steps, nb_max_start_steps, start_step_policy, verbose)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m done:\n\u001b[0;32m    339\u001b[0m     callbacks\u001b[39m.\u001b[39mon_step_begin(episode_step)\n\u001b[1;32m--> 341\u001b[0m     action \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(observation)\n\u001b[0;32m    342\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m         action \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessor\u001b[39m.\u001b[39mprocess_action(action)\n",
      "File \u001b[1;32mc:\\Users\\Xteve Sing\\.conda\\envs\\rltest\\lib\\site-packages\\rl\\agents\\dqn.py:224\u001b[0m, in \u001b[0;36mDQNAgent.forward\u001b[1;34m(self, observation)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, observation):\n\u001b[0;32m    222\u001b[0m     \u001b[39m# Select an action.\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory\u001b[39m.\u001b[39mget_recent_state(observation)\n\u001b[1;32m--> 224\u001b[0m     q_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_q_values(state)\n\u001b[0;32m    225\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n\u001b[0;32m    226\u001b[0m         action \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy\u001b[39m.\u001b[39mselect_action(q_values\u001b[39m=\u001b[39mq_values)\n",
      "File \u001b[1;32mc:\\Users\\Xteve Sing\\.conda\\envs\\rltest\\lib\\site-packages\\rl\\agents\\dqn.py:68\u001b[0m, in \u001b[0;36mAbstractDQNAgent.compute_q_values\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_q_values\u001b[39m(\u001b[39mself\u001b[39m, state):\n\u001b[1;32m---> 68\u001b[0m     q_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_batch_q_values([state])\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m     69\u001b[0m     \u001b[39massert\u001b[39;00m q_values\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnb_actions,)\n\u001b[0;32m     70\u001b[0m     \u001b[39mreturn\u001b[39;00m q_values\n",
      "File \u001b[1;32mc:\\Users\\Xteve Sing\\.conda\\envs\\rltest\\lib\\site-packages\\rl\\agents\\dqn.py:63\u001b[0m, in \u001b[0;36mAbstractDQNAgent.compute_batch_q_values\u001b[1;34m(self, state_batch)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_batch_q_values\u001b[39m(\u001b[39mself\u001b[39m, state_batch):\n\u001b[0;32m     62\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_state_batch(state_batch)\n\u001b[1;32m---> 63\u001b[0m     q_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict_on_batch(batch)\n\u001b[0;32m     64\u001b[0m     \u001b[39massert\u001b[39;00m q_values\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (\u001b[39mlen\u001b[39m(state_batch), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnb_actions)\n\u001b[0;32m     65\u001b[0m     \u001b[39mreturn\u001b[39;00m q_values\n",
      "File \u001b[1;32mc:\\Users\\Xteve Sing\\.conda\\envs\\rltest\\lib\\site-packages\\keras\\engine\\training_v1.py:1304\u001b[0m, in \u001b[0;36mModel.predict_on_batch\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   1299\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m   1300\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`predict_on_batch` is not supported for models distributed \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1301\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwith tf.distribute.Strategy.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1302\u001b[0m     )\n\u001b[0;32m   1303\u001b[0m \u001b[39m# Validate and standardize user data.\u001b[39;00m\n\u001b[1;32m-> 1304\u001b[0m inputs, _, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_standardize_user_data(\n\u001b[0;32m   1305\u001b[0m     x, extract_tensors_from_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m   1306\u001b[0m )\n\u001b[0;32m   1307\u001b[0m \u001b[39m# If `self._distribution_strategy` is True, then we are in a replica\u001b[39;00m\n\u001b[0;32m   1308\u001b[0m \u001b[39m# context at this point.\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_eagerly \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_distribution_strategy:\n",
      "File \u001b[1;32mc:\\Users\\Xteve Sing\\.conda\\envs\\rltest\\lib\\site-packages\\keras\\engine\\training_v1.py:2649\u001b[0m, in \u001b[0;36mModel._standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2640\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   2641\u001b[0m     \u001b[39mnot\u001b[39;00m run_eagerly\n\u001b[0;32m   2642\u001b[0m     \u001b[39mand\u001b[39;00m is_build_called\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2645\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(_is_symbolic_tensor(v) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m all_inputs)\n\u001b[0;32m   2646\u001b[0m ):\n\u001b[0;32m   2647\u001b[0m     \u001b[39mreturn\u001b[39;00m [], [], \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 2649\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_standardize_tensors(\n\u001b[0;32m   2650\u001b[0m     x,\n\u001b[0;32m   2651\u001b[0m     y,\n\u001b[0;32m   2652\u001b[0m     sample_weight,\n\u001b[0;32m   2653\u001b[0m     run_eagerly\u001b[39m=\u001b[39;49mrun_eagerly,\n\u001b[0;32m   2654\u001b[0m     dict_inputs\u001b[39m=\u001b[39;49mdict_inputs,\n\u001b[0;32m   2655\u001b[0m     is_dataset\u001b[39m=\u001b[39;49mis_dataset,\n\u001b[0;32m   2656\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[0;32m   2657\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   2658\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Xteve Sing\\.conda\\envs\\rltest\\lib\\site-packages\\keras\\engine\\training_v1.py:2690\u001b[0m, in \u001b[0;36mModel._standardize_tensors\u001b[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   2687\u001b[0m \u001b[39m# Standardize the inputs.\u001b[39;00m\n\u001b[0;32m   2688\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(x, (tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset, tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset)):\n\u001b[0;32m   2689\u001b[0m     \u001b[39m# TODO(fchollet): run static checks with dataset output shape(s).\u001b[39;00m\n\u001b[1;32m-> 2690\u001b[0m     x \u001b[39m=\u001b[39m training_utils_v1\u001b[39m.\u001b[39;49mstandardize_input_data(\n\u001b[0;32m   2691\u001b[0m         x,\n\u001b[0;32m   2692\u001b[0m         feed_input_names,\n\u001b[0;32m   2693\u001b[0m         feed_input_shapes,\n\u001b[0;32m   2694\u001b[0m         check_batch_axis\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,  \u001b[39m# Don't enforce the batch size.\u001b[39;49;00m\n\u001b[0;32m   2695\u001b[0m         exception_prefix\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39minput\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   2696\u001b[0m     )\n\u001b[0;32m   2698\u001b[0m \u001b[39m# Get typespecs for the input data and sanitize it if necessary.\u001b[39;00m\n\u001b[0;32m   2699\u001b[0m \u001b[39m# TODO(momernick): This should be capable of doing full input validation\u001b[39;00m\n\u001b[0;32m   2700\u001b[0m \u001b[39m# at all times - validate that this is so and refactor the\u001b[39;00m\n\u001b[0;32m   2701\u001b[0m \u001b[39m# standardization code.\u001b[39;00m\n\u001b[0;32m   2702\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset):\n",
      "File \u001b[1;32mc:\\Users\\Xteve Sing\\.conda\\envs\\rltest\\lib\\site-packages\\keras\\engine\\training_utils_v1.py:733\u001b[0m, in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    727\u001b[0m             \u001b[39mfor\u001b[39;00m dim, ref_dim \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(data_shape, shape):\n\u001b[0;32m    728\u001b[0m                 \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    729\u001b[0m                     ref_dim \u001b[39m!=\u001b[39m dim\n\u001b[0;32m    730\u001b[0m                     \u001b[39mand\u001b[39;00m ref_dim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    731\u001b[0m                     \u001b[39mand\u001b[39;00m dim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    732\u001b[0m                 ):\n\u001b[1;32m--> 733\u001b[0m                     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    734\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mError when checking \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    735\u001b[0m                         \u001b[39m+\u001b[39m exception_prefix\n\u001b[0;32m    736\u001b[0m                         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m: expected \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    737\u001b[0m                         \u001b[39m+\u001b[39m names[i]\n\u001b[0;32m    738\u001b[0m                         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m to have shape \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    739\u001b[0m                         \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(shape)\n\u001b[0;32m    740\u001b[0m                         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m but got array with shape \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    741\u001b[0m                         \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(data_shape)\n\u001b[0;32m    742\u001b[0m                     )\n\u001b[0;32m    743\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected flatten_4_input to have shape (1, 4) but got array with shape (1, 2)"
     ]
    }
   ],
   "source": [
    "results = agent.test(env, nb_episodes=10, visualize=False)\n",
    "print(np.mean(results.history['episode_reward']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf211",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
